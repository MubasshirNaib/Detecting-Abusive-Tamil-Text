{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10410904,"sourceType":"datasetVersion","datasetId":6451904},{"sourceId":10414122,"sourceType":"datasetVersion","datasetId":6454274}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n# # Import required libraries\n# import pandas as pd\n# from sklearn.model_selection import train_test_split\n# from sklearn.feature_extraction.text import TfidfVectorizer\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.metrics import classification_report, accuracy_score\n\n# # Load the training dataset\n# train_data = pd.read_csv(\"/kaggle/input/train-data/AWT_train.csv\")\n\n# # Check for missing values in the \"Class\" column\n# print(\"Number of missing values in 'Class' before cleaning:\", train_data[\"Class\"].isna().sum())\n\n# # Drop rows with missing values in the \"Class\" column\n# train_data = train_data.dropna(subset=[\"Class\"])\n\n# # Map non-numeric labels to integers\n# label_mapping = {\"Non-Abusive\": 0, \"Abusive\": 1}\n# train_data[\"Class\"] = train_data[\"Class\"].map(label_mapping)\n\n# # Ensure there are no NaN values after mapping\n# train_data = train_data.dropna(subset=[\"Class\"])\n# print(\"Number of missing values in 'Class' after mapping and cleaning:\", train_data[\"Class\"].isna().sum())\n\n# # Split the training data into train and validation sets\n# X_train, X_val, y_train, y_val = train_test_split(\n#     train_data[\"Text\"], train_data[\"Class\"], test_size=0.2, random_state=42\n# )\n\n# # Ensure there are no NaN values in training and validation labels\n# print(\"NaN in y_train:\", pd.isna(y_train).sum())\n# print(\"NaN in y_val:\", pd.isna(y_val).sum())\n\n# # Text Vectorization using TF-IDF\n# vectorizer = TfidfVectorizer(max_features=5000)\n# X_train_tfidf = vectorizer.fit_transform(X_train)\n# X_val_tfidf = vectorizer.transform(X_val)\n\n# # Initialize and Train the Logistic Regression Model\n# model = LogisticRegression()\n# model.fit(X_train_tfidf, y_train)\n\n# # Evaluate on the validation set\n# y_val_pred = model.predict(X_val_tfidf)\n# print(\"Validation Classification Report:\\n\", classification_report(y_val, y_val_pred))\n# print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n\n# # Load the test dataset\n# test_data = pd.read_csv(\"/kaggle/input/test-data/test_predictions.csv\")\n\n# # Vectorize the test data\n# X_test_tfidf = vectorizer.transform(test_data[\"Text\"])\n\n# # Make predictions on the test dataset\n# test_predictions = model.predict(X_test_tfidf)\n\n# # Convert predictions back to original label names\n# reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n# test_predictions_labels = [reverse_label_mapping[pred] for pred in test_predictions]\n\n# # Save predictions to a CSV file\n# output = pd.DataFrame({\"Text\": test_data[\"Text\"], \"Predicted_Class\": test_predictions_labels})\n# output.to_csv(\"test_predictions.csv\", index=False)\n# print(\"Predictions saved to 'test_predictions.csv'.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-09T09:57:58.199627Z","iopub.execute_input":"2025-01-09T09:57:58.199875Z","iopub.status.idle":"2025-01-09T09:57:59.384015Z","shell.execute_reply.started":"2025-01-09T09:57:58.199849Z","shell.execute_reply":"2025-01-09T09:57:59.383080Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install transformers datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T10:00:10.721288Z","iopub.execute_input":"2025-01-09T10:00:10.721602Z","iopub.status.idle":"2025-01-09T10:00:15.160523Z","shell.execute_reply.started":"2025-01-09T10:00:10.721578Z","shell.execute_reply":"2025-01-09T10:00:15.159493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install evaluate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T10:04:46.230428Z","iopub.execute_input":"2025-01-09T10:04:46.230770Z","iopub.status.idle":"2025-01-09T10:04:49.711524Z","shell.execute_reply.started":"2025-01-09T10:04:46.230744Z","shell.execute_reply":"2025-01-09T10:04:49.710284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Import required libraries\n# import pandas as pd\n# from datasets import Dataset\n# from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n# import torch\n# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import accuracy_score, precision_score, recall_score\n\n# # Load the dataset\n# train_data = pd.read_csv(\"/kaggle/input/train-data/AWT_train.csv\")\n# test_data = pd.read_csv(\"/kaggle/input/test1-1-data/AWT_test_without_labels.csv\")\n\n# # Map the labels\n# label_mapping = {\"Non-Abusive\": 0, \"Abusive\": 1}\n# train_data[\"Class\"] = train_data[\"Class\"].map(label_mapping)\n\n# # Ensure no missing values\n# train_data = train_data.dropna(subset=[\"Class\"])\n\n# # Split the dataset into training and validation sets\n# train_texts, val_texts, train_labels, val_labels = train_test_split(\n#     train_data[\"Text\"], train_data[\"Class\"], test_size=0.1, random_state=42\n# )\n\n# # Initialize the tokenizer\n# tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n\n# # Tokenize the dataset\n# def preprocess_function(texts, labels):\n#     tokenized = tokenizer(list(texts), padding=\"max_length\", truncation=True, max_length=128)\n#     tokenized[\"labels\"] = labels\n#     return tokenized\n\n# train_encodings = preprocess_function(train_texts, list(train_labels))\n# val_encodings = preprocess_function(val_texts, list(val_labels))\n\n# # Convert tokenized data to PyTorch datasets\n# class CustomDataset(torch.utils.data.Dataset):\n#     def __init__(self, encodings):\n#         self.encodings = encodings\n\n#     def __len__(self):\n#         return len(self.encodings[\"input_ids\"])\n\n#     def __getitem__(self, idx):\n#         return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\n# train_dataset = CustomDataset(train_encodings)\n# val_dataset = CustomDataset(val_encodings)\n\n# # Initialize the model\n# model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=1)\n\n# # Define the compute_metrics function\n# def compute_metrics(pred):\n#     predictions, labels = pred\n#     preds = (torch.sigmoid(torch.tensor(predictions)) > 0.5).int()\n#     labels = torch.tensor(labels).int()\n    \n#     accuracy = accuracy_score(labels, preds)\n#     precision = precision_score(labels, preds)\n#     recall = recall_score(labels, preds)\n    \n#     return {\n#         \"accuracy\": accuracy,\n#         \"precision\": precision,\n#         \"recall\": recall,\n#     }\n\n# # Define the Trainer arguments\n# training_args = TrainingArguments(\n#     output_dir=\"./results\",               # Output directory\n#     eval_strategy=\"epoch\",               # Evaluate every epoch\n#     save_strategy=\"epoch\",               # Save every epoch\n#     learning_rate=5e-5,                  # Learning rate\n#     per_device_train_batch_size=16,      # Batch size for training\n#     per_device_eval_batch_size=16,       # Batch size for evaluation\n#     num_train_epochs=3,                  # Number of epochs\n#     weight_decay=0.01,                   # Weight decay\n#     logging_dir=\"./logs\",                # Logging directory\n#     logging_steps=10,                    # Log every 10 steps\n#     report_to=\"none\",                    # Disable W&B logging\n# )\n\n# # Define the Trainer\n# trainer = Trainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=train_dataset,\n#     eval_dataset=val_dataset,  # Add validation dataset\n#     tokenizer=tokenizer,\n#     compute_metrics=compute_metrics,  # Add the metrics function\n# )\n\n# # Train the model\n# trainer.train()\n\n# # Make predictions on the test set\n# test_encodings = preprocess_function(test_data[\"Text\"], [0] * len(test_data))\n# test_dataset = CustomDataset(test_encodings)\n\n# predictions = trainer.predict(test_dataset)\n# preds = torch.sigmoid(torch.tensor(predictions.predictions)).numpy()\n# pred_labels = (preds > 0.5).astype(int).flatten()\n\n# # Save predictions\n# test_data[\"Predicted_Class\"] = pred_labels\n# test_data[\"Predicted_Class\"] = test_data[\"Predicted_Class\"].map({0: \"Non-Abusive\", 1: \"Abusive\"})\n# test_data.to_csv(\"test_predictions.csv\", index=False)\n# print(\"Predictions saved to 'test_predictions.csv'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T17:03:18.291389Z","iopub.execute_input":"2025-01-09T17:03:18.291742Z","iopub.status.idle":"2025-01-09T17:05:58.660845Z","shell.execute_reply.started":"2025-01-09T17:03:18.291718Z","shell.execute_reply":"2025-01-09T17:05:58.660145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\n# Load the dataset\ntrain_data = pd.read_csv(\"/kaggle/input/train-data/AWT_train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/test1-1-data/AWT_test_without_labels.csv\")\n\n# Map the labels\nlabel_mapping = {\"Non-Abusive\": 0, \"Abusive\": 1}\ntrain_data[\"Class\"] = train_data[\"Class\"].map(label_mapping)\n\n# Ensure no missing values\ntrain_data = train_data.dropna(subset=[\"Class\"])\n\n# Split the dataset into training and validation sets\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    train_data[\"Text\"], train_data[\"Class\"], test_size=0.2, random_state=42\n)\n\n# Initialize the tokenizer\ntokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")\n\n# Tokenize the dataset\ndef preprocess_function(texts, labels):\n    tokenized = tokenizer(list(texts), padding=\"max_length\", truncation=True, max_length=128)\n    tokenized[\"labels\"] = labels\n    return tokenized\n\ntrain_encodings = preprocess_function(train_texts, list(train_labels))\nval_encodings = preprocess_function(val_texts, list(val_labels))\n\n# Convert tokenized data to PyTorch datasets\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])\n\n    def __getitem__(self, idx):\n        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\ntrain_dataset = CustomDataset(train_encodings)\nval_dataset = CustomDataset(val_encodings)\n\n# Initialize the model\nmodel = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-multilingual-cased\", num_labels=1)\n\n# Define the compute_metrics function\ndef compute_metrics(pred):\n    predictions, labels = pred\n    preds = (torch.sigmoid(torch.tensor(predictions)) > 0.5).int()\n    labels = torch.tensor(labels).int()\n    \n    accuracy = accuracy_score(labels, preds)\n    precision = precision_score(labels, preds)\n    recall = recall_score(labels, preds)\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0  # F1 Score\n    \n    return {\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1,  # F1 Score\n    }\n\n# Define the Trainer arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",               # Output directory\n    eval_strategy=\"epoch\",                # Evaluate every epoch\n    save_strategy=\"epoch\",                # Save every epoch\n    learning_rate=5e-5,                   # Learning rate\n    per_device_train_batch_size=16,       # Batch size for training\n    per_device_eval_batch_size=16,        # Batch size for evaluation\n    num_train_epochs=7,                   # Number of epochs\n    weight_decay=0.003,                    # Weight decay\n    logging_dir=\"./logs\",                 # Logging directory\n    logging_steps=10,                     # Log every 10 steps\n    report_to=\"none\",                     # Disable W&B logging\n)\n\n# Define the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,  # Add validation dataset\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,  # Add the metrics function\n)\n\n# Train the model\ntrainer.train()\n\n# Make predictions on the test set\ntest_encodings = preprocess_function(test_data[\"Text\"], [0] * len(test_data))\ntest_dataset = CustomDataset(test_encodings)\n\npredictions = trainer.predict(test_dataset)\npreds = torch.sigmoid(torch.tensor(predictions.predictions)).numpy()\npred_labels = (preds > 0.5).astype(int).flatten()\n\n# Save predictions\ntest_data[\"Predicted_Class\"] = pred_labels\ntest_data[\"Predicted_Class\"] = test_data[\"Predicted_Class\"].map({0: \"Non-Abusive\", 1: \"Abusive\"})\ntest_data.to_csv(\"test_predictions_distilbert.csv\", index=False)\nprint(\"Predictions saved to 'test_predictions_distilbert.csv'.\") \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T15:50:00.127129Z","iopub.execute_input":"2025-01-27T15:50:00.127480Z","iopub.status.idle":"2025-01-27T15:53:45.929979Z","shell.execute_reply.started":"2025-01-27T15:50:00.127451Z","shell.execute_reply":"2025-01-27T15:53:45.929208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\n# Load the dataset\ntrain_data = pd.read_csv(\"/kaggle/input/train-data/AWT_train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/test1-1-data/AWT_test_without_labels.csv\")\n\n# Map the labels\nlabel_mapping = {\"Non-Abusive\": 0, \"Abusive\": 1}\ntrain_data[\"Class\"] = train_data[\"Class\"].map(label_mapping)\n\n# Ensure no missing values\ntrain_data = train_data.dropna(subset=[\"Class\"])\n\n# Split the dataset into training and validation sets\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    train_data[\"Text\"], train_data[\"Class\"], test_size=0.1, random_state=42\n)\n\n# Initialize the tokenizer\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n\n# Tokenize the dataset\ndef preprocess_function(texts, labels):\n    tokenized = tokenizer(list(texts), padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n    tokenized[\"labels\"] = labels\n    return tokenized\n\ntrain_encodings = preprocess_function(train_texts, list(train_labels))\nval_encodings = preprocess_function(val_texts, list(val_labels))\n\n# Convert tokenized data to PyTorch datasets\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])\n\n    def __getitem__(self, idx):\n        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\ntrain_dataset = CustomDataset(train_encodings)\nval_dataset = CustomDataset(val_encodings)\n\n# Initialize the model\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=1)\n\n# Define the compute_metrics function\ndef compute_metrics(pred):\n    predictions, labels = pred\n    preds = (torch.sigmoid(torch.tensor(predictions)) > 0.5).int()\n    labels = torch.tensor(labels).int()\n    \n    accuracy = accuracy_score(labels, preds)\n    precision = precision_score(labels, preds)\n    recall = recall_score(labels, preds)\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    \n    return {\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1,\n    }\n\n# Define the TrainingArguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",               # Output directory\n    eval_strategy=\"epoch\",                # Evaluate every epoch\n    save_strategy=\"epoch\",                # Save every epoch\n    learning_rate=5e-5,                   # Learning rate\n    per_device_train_batch_size=16,       # Batch size for training\n    per_device_eval_batch_size=16,        # Batch size for evaluation\n    num_train_epochs=7,                   # Number of epochs\n    weight_decay=0.003,                   # Weight decay\n    logging_dir=\"./logs\",                 # Logging directory\n    logging_steps=10,                     # Log every 10 steps\n    report_to=\"none\",                     # Disable W&B logging\n)\n\n# Define the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Train the model\ntrainer.train()\n\n# Make predictions on the test set\ntest_encodings = preprocess_function(test_data[\"Text\"], [0] * len(test_data))\ntest_dataset = CustomDataset(test_encodings)\n\npredictions = trainer.predict(test_dataset)\npreds = torch.sigmoid(torch.tensor(predictions.predictions)).numpy()\npred_labels = (preds > 0.5).astype(int).flatten()\n\n# Save predictions with only \"Id\" and \"Labels\"\ntest_data[\"Predicted_Class\"] = pred_labels\ntest_data[\"Predicted_Class\"] = test_data[\"Predicted_Class\"].map({0: \"Non-Abusive\", 1: \"Abusive\"})\ntest_data.to_csv(\"test_predictions_bert.csv\", index=False)\nprint(\"Predictions saved to 'test_predictions_bert.csv'.\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T10:26:04.651233Z","iopub.execute_input":"2025-01-27T10:26:04.651540Z","iopub.status.idle":"2025-01-27T10:32:16.022689Z","shell.execute_reply.started":"2025-01-27T10:26:04.651517Z","shell.execute_reply":"2025-01-27T10:32:16.022002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd\n\n# # Load the predictions\n# test_predictions = pd.read_csv(\"test_predictions_bert.csv\")\n\n# # Create the file with only 'id' and 'Predicted_Class'\n# prediction_file = test_predictions[['id', 'Predicted_Class']]\n\n# # Save the file\n# prediction_file.to_csv(\"test_predictions_bert_only_id_labels.csv\", index=False)\n\n# print(\"Prediction file with 'id' and 'Predicted_Class' saved as 'test_predictions_bert_only_id_labels.csv'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T15:45:13.956637Z","iopub.execute_input":"2025-01-10T15:45:13.957128Z","iopub.status.idle":"2025-01-10T15:45:14.012451Z","shell.execute_reply.started":"2025-01-10T15:45:13.957083Z","shell.execute_reply":"2025-01-10T15:45:14.011265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd\n# from datasets import Dataset\n# from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n# import torch\n# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import accuracy_score, precision_score, recall_score\n\n# # Load the dataset\n# train_data = pd.read_csv(\"/kaggle/input/train-data/AWT_train.csv\")\n# test_data = pd.read_csv(\"/kaggle/input/test1-1-data/AWT_test_without_labels.csv\")\n\n# # Map the labels\n# label_mapping = {\"Non-Abusive\": 0, \"Abusive\": 1}\n# train_data[\"Class\"] = train_data[\"Class\"].map(label_mapping)\n\n# # Ensure no missing values\n# train_data = train_data.dropna(subset=[\"Class\"])\n\n# # Split the dataset into training and validation sets\n# train_texts, val_texts, train_labels, val_labels = train_test_split(\n#     train_data[\"Text\"], train_data[\"Class\"], test_size=0.1, random_state=42\n# )\n\n# # Initialize the tokenizer\n# tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n\n# # Tokenize the dataset\n# def preprocess_function(texts, labels):\n#     tokenized = tokenizer(list(texts), padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n#     tokenized[\"labels\"] = labels\n#     return tokenized\n\n# train_encodings = preprocess_function(train_texts, list(train_labels))\n# val_encodings = preprocess_function(val_texts, list(val_labels))\n\n# # Convert tokenized data to PyTorch datasets\n# class CustomDataset(torch.utils.data.Dataset):\n#     def __init__(self, encodings):\n#         self.encodings = encodings\n\n#     def __len__(self):\n#         return len(self.encodings[\"input_ids\"])\n\n#     def __getitem__(self, idx):\n#         return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\n# train_dataset = CustomDataset(train_encodings)\n# val_dataset = CustomDataset(val_encodings)\n\n# # Initialize the model\n# model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=1)\n\n# # Define the compute_metrics function\n# def compute_metrics(pred):\n#     predictions, labels = pred\n#     preds = (torch.sigmoid(torch.tensor(predictions)) > 0.5).int()\n#     labels = torch.tensor(labels).int()\n    \n#     accuracy = accuracy_score(labels, preds)\n#     precision = precision_score(labels, preds)\n#     recall = recall_score(labels, preds)\n#     f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0  # F1 Score\n    \n#     return {\n#         \"accuracy\": accuracy,\n#         \"precision\": precision,\n#         \"recall\": recall,\n#         \"f1\": f1,  # F1 Score\n#     }\n\n# # Define the TrainingArguments\n# training_args = TrainingArguments(\n#     output_dir=\"./results\",               # Output directory\n#     eval_strategy=\"epoch\",                # Evaluate every epoch\n#     save_strategy=\"epoch\",                # Save every epoch\n#     learning_rate=5e-5,                   # Learning rate (try adjusting this)\n#     per_device_train_batch_size=16,       # Batch size for training\n#     per_device_eval_batch_size=16,        # Batch size for evaluation\n#     num_train_epochs=7,                   # Number of epochs\n#     weight_decay=0.003,                    # Weight decay\n#     logging_dir=\"./logs\",                 # Logging directory\n#     logging_steps=10,                     # Log every 10 steps\n#     report_to=\"none\",                     # Disable W&B logging\n# )\n\n# # Define the Trainer\n# trainer = Trainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=train_dataset,\n#     eval_dataset=val_dataset,  # Add validation dataset\n#     tokenizer=tokenizer,\n#     compute_metrics=compute_metrics,  # Add the metrics function\n# )\n\n# # Train the model\n# trainer.train()\n\n# # Make predictions on the test set\n# test_encodings = preprocess_function(test_data[\"Text\"], [0] * len(test_data))\n# test_dataset = CustomDataset(test_encodings)\n\n# predictions = trainer.predict(test_dataset)\n# preds = torch.sigmoid(torch.tensor(predictions.predictions)).numpy()\n# pred_labels = (preds > 0.5).astype(int).flatten()\n\n# # Save predictions\n# test_data[\"Labels\"] = pred_labels\n# test_data[\"Labels\"] = test_data[\"Labels\"].map({0: \"Non-Abusive\", 1: \"Abusive\"})\n# #test_data.to_csv(\"test_predictions_bert.csv\", index=False)\n# #print(\"Predictions saved to 'test_predictions_bert.csv'.\") \n# # Load the predictions\n# #test_predictions = pd.read_csv(\"test_predictions_bert.csv\")\n\n# # Create the file with only 'id' and 'Predicted_Class'\n# prediction_file = test_data[['id', 'Labels']]\n\n# # Save the file\n# prediction_file.to_csv(\"test_predictions_bert_only_id_labels1.csv\", index=False)\n\n# print(\"Prediction file with 'id' and 'Predicted_Class' saved as 'test_predictions_bert_only_id_labels.csv'.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T10:16:03.964461Z","iopub.execute_input":"2025-01-27T10:16:03.964832Z","iopub.status.idle":"2025-01-27T10:22:17.836326Z","shell.execute_reply.started":"2025-01-27T10:16:03.964800Z","shell.execute_reply":"2025-01-27T10:22:17.835564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd\n\n# # Load the predictions\n# test_predictions = pd.read_csv(\"test_predictions_bert.csv\")\n\n# # Create the file with only 'id' and 'Predicted_Class'\n# prediction_file = test_predictions[['id', 'Predicted_Class']]\n\n# # Save the file\n# prediction_file.to_csv(\"test_predictions_bert_only_id_labels.csv\", index=False)\n\n# print(\"Prediction file with 'id' and 'Predicted_Class' saved as 'test_predictions_bert_only_id_labels.csv'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T15:43:04.978947Z","iopub.execute_input":"2025-01-10T15:43:04.979251Z","iopub.status.idle":"2025-01-10T15:43:05.020021Z","shell.execute_reply.started":"2025-01-10T15:43:04.979229Z","shell.execute_reply":"2025-01-10T15:43:05.018866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\nfrom transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, Trainer, TrainingArguments\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\n# Load the dataset\ntrain_data = pd.read_csv(\"/kaggle/input/train-data/AWT_train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/test1-1-data/AWT_test_without_labels.csv\")\n\n# Map the labels\nlabel_mapping = {\"Non-Abusive\": 0, \"Abusive\": 1}\ntrain_data[\"Class\"] = train_data[\"Class\"].map(label_mapping)\n\n# Ensure no missing values\ntrain_data = train_data.dropna(subset=[\"Class\"])\n\n# Split the dataset into training and validation sets\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    train_data[\"Text\"], train_data[\"Class\"], test_size=0.1, random_state=42\n)\n\n# Initialize the tokenizer\ntokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n\n# Tokenize the dataset\ndef preprocess_function(texts, labels):\n    tokenized = tokenizer(list(texts), padding=\"max_length\", truncation=True, max_length=128)\n    tokenized[\"labels\"] = labels\n    return tokenized\n\ntrain_encodings = preprocess_function(train_texts, list(train_labels))\nval_encodings = preprocess_function(val_texts, list(val_labels))\n\n# Convert tokenized data to PyTorch datasets\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])\n\n    def __getitem__(self, idx):\n        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\ntrain_dataset = CustomDataset(train_encodings)\nval_dataset = CustomDataset(val_encodings)\n\n# Initialize the model\nmodel = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=1)\n\n# Define the compute_metrics function\ndef compute_metrics(pred):\n    predictions, labels = pred\n    preds = (torch.sigmoid(torch.tensor(predictions)) > 0.5).int()\n    labels = torch.tensor(labels).int()\n    \n    accuracy = accuracy_score(labels, preds)\n    precision = precision_score(labels, preds)\n    recall = recall_score(labels, preds)\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0  # F1 Score\n    \n    return {\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1,  # F1 Score\n    }\n\n# Define the Trainer arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",               # Output directory\n    eval_strategy=\"epoch\",                # Evaluate every epoch\n    save_strategy=\"epoch\",                # Save every epoch\n    learning_rate=5e-5,                   # Learning rate\n    per_device_train_batch_size=16,       # Batch size for training\n    per_device_eval_batch_size=16,        # Batch size for evaluation\n    num_train_epochs=3,                   # Number of epochs\n    weight_decay=0.003,                    # Weight decay\n    logging_dir=\"./logs\",                 # Logging directory\n    logging_steps=10,                     # Log every 10 steps\n    report_to=\"none\",                     # Disable W&B logging\n)\n\n# Define the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,  # Add validation dataset\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,  # Add the metrics function\n)\n\n# Train the model\ntrainer.train()\n\n# Make predictions on the test set\ntest_encodings = preprocess_function(test_data[\"Text\"], [0] * len(test_data))\ntest_dataset = CustomDataset(test_encodings)\n\npredictions = trainer.predict(test_dataset)\npreds = torch.sigmoid(torch.tensor(predictions.predictions)).numpy()\npred_labels = (preds > 0.5).astype(int).flatten()\n\n# Save predictions\ntest_data[\"Predicted_Class\"] = pred_labels\ntest_data[\"Predicted_Class\"] = test_data[\"Predicted_Class\"].map({0: \"Non-Abusive\", 1: \"Abusive\"})\ntest_data.to_csv(\"test_predictions_xlmr.csv\", index=False)\nprint(\"Predictions saved to 'test_predictions_xlmr.csv'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T13:33:14.832792Z","iopub.execute_input":"2025-01-27T13:33:14.833100Z","iopub.status.idle":"2025-01-27T13:37:06.126002Z","shell.execute_reply.started":"2025-01-27T13:33:14.833075Z","shell.execute_reply":"2025-01-27T13:37:06.125085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Import required libraries\n# import pandas as pd\n# from sklearn.model_selection import train_test_split\n# from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.svm import SVC\n# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.naive_bayes import MultinomialNB\n# from sklearn.metrics import classification_report, accuracy_score\n\n# # Load the training dataset\n# train_data = pd.read_csv(\"/kaggle/input/train-data/AWT_train.csv\")\n\n# # Check for missing values in the \"Class\" column\n# print(\"Number of missing values in 'Class' before cleaning:\", train_data[\"Class\"].isna().sum())\n\n# # Drop rows with missing values in the \"Class\" column\n# train_data = train_data.dropna(subset=[\"Class\"])\n\n# # Map non-numeric labels to integers\n# label_mapping = {\"Non-Abusive\": 0, \"Abusive\": 1}\n# train_data[\"Class\"] = train_data[\"Class\"].map(label_mapping)\n\n# # Ensure there are no NaN values after mapping\n# train_data = train_data.dropna(subset=[\"Class\"])\n# print(\"Number of missing values in 'Class' after mapping and cleaning:\", train_data[\"Class\"].isna().sum())\n\n# # Split the training data into train and validation sets\n# X_train, X_val, y_train, y_val = train_test_split(\n#     train_data[\"Text\"], train_data[\"Class\"], test_size=0.2, random_state=42\n# )\n\n# # Ensure there are no NaN values in training and validation labels\n# print(\"NaN in y_train:\", pd.isna(y_train).sum())\n# print(\"NaN in y_val:\", pd.isna(y_val).sum())\n\n# # Define a function to train and evaluate models\n# def train_and_evaluate(models, feature_extractor, feature_name):\n#     # Transform text data using the feature extractor\n#     X_train_features = feature_extractor.fit_transform(X_train)\n#     X_val_features = feature_extractor.transform(X_val)\n    \n#     # Iterate over the models and train them\n#     for model_name, model in models.items():\n#         print(f\"\\nTraining {model_name} with {feature_name} features...\")\n#         model.fit(X_train_features, y_train)\n#         y_val_pred = model.predict(X_val_features)\n        \n#         # Evaluate the model\n#         print(f\"\\nValidation Results for {model_name} ({feature_name}):\")\n#         print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n#         print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n\n# # Define models to train\n# models = {\n#     \"Logistic Regression\": LogisticRegression(),\n#     \"SVM\": SVC(),\n#     \"Random Forest\": RandomForestClassifier(),\n#     \"Multinomial Naive Bayes\": MultinomialNB()\n# }\n\n# # Evaluate with TF-IDF features\n# print(\"\\nUsing TF-IDF features:\")\n# tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n# train_and_evaluate(models, tfidf_vectorizer, \"TF-IDF\")\n\n# # Evaluate with Bag of Words (BoW) features\n# print(\"\\nUsing Bag of Words (BoW) features:\")\n# bow_vectorizer = CountVectorizer(max_features=5000)\n# train_and_evaluate(models, bow_vectorizer, \"BoW\")\n\n# # Load the test dataset\n# test_data = pd.read_csv(\"/kaggle/input/test1-1-data/AWT_test_without_labels.csv\")\n\n# # Transform test data using the TF-IDF vectorizer\n# X_test_tfidf = tfidf_vectorizer.transform(test_data[\"Text\"])\n\n# # Make predictions on the test dataset using the best-performing model (e.g., Logistic Regression)\n# best_model = LogisticRegression()  # Replace with your chosen model if needed\n# best_model.fit(tfidf_vectorizer.fit_transform(X_train), y_train)  # Retrain on the full training data\n# test_predictions = best_model.predict(X_test_tfidf)\n\n# # Convert predictions back to original label names\n# reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n# test_predictions_labels = [reverse_label_mapping[pred] for pred in test_predictions]\n\n# # Save predictions to a CSV file\n# output = pd.DataFrame({\"Text\": test_data[\"Text\"], \"Predicted_Class\": test_predictions_labels})\n# output.to_csv(\"test_predictions.csv\", index=False)\n# print(\"Predictions saved to 'test_predictions.csv'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T13:39:18.506720Z","iopub.execute_input":"2025-01-27T13:39:18.507090Z","iopub.status.idle":"2025-01-27T13:39:22.694848Z","shell.execute_reply.started":"2025-01-27T13:39:18.507049Z","shell.execute_reply":"2025-01-27T13:39:22.694029Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import required libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Load the training dataset\ntrain_data = pd.read_csv(\"/kaggle/input/train-data/AWT_train.csv\")\n\n# Check for missing values in the \"Class\" column\nprint(\"Number of missing values in 'Class' before cleaning:\", train_data[\"Class\"].isna().sum())\n\n# Drop rows with missing values in the \"Class\" column\ntrain_data = train_data.dropna(subset=[\"Class\"])\n\n# Map non-numeric labels to integers\nlabel_mapping = {\"Non-Abusive\": 0, \"Abusive\": 1}\ntrain_data[\"Class\"] = train_data[\"Class\"].map(label_mapping)\n\n# Ensure there are no NaN values after mapping\ntrain_data = train_data.dropna(subset=[\"Class\"])\nprint(\"Number of missing values in 'Class' after mapping and cleaning:\", train_data[\"Class\"].isna().sum())\n\n# Split the training data into train and validation sets\nX_train, X_val, y_train, y_val = train_test_split(\n    train_data[\"Text\"], train_data[\"Class\"], test_size=0.2, random_state=42\n)\n\n# Ensure there are no NaN values in training and validation labels\nprint(\"NaN in y_train:\", pd.isna(y_train).sum())\nprint(\"NaN in y_val:\", pd.isna(y_val).sum())\n\n# Define a function to train and evaluate models\ndef train_and_evaluate(models, feature_extractor, feature_name):\n    # Transform text data using the feature extractor\n    X_train_features = feature_extractor.fit_transform(X_train)\n    X_val_features = feature_extractor.transform(X_val)\n    \n    # Iterate over the models and train them\n    for model_name, model in models.items():\n        print(f\"\\nTraining {model_name} with {feature_name} features...\")\n        model.fit(X_train_features, y_train)\n        y_val_pred = model.predict(X_val_features)\n        \n        # Evaluate the model\n        print(f\"\\nValidation Results for {model_name} ({feature_name}):\")\n        print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred, digits=4))\n        accuracy = accuracy_score(y_val, y_val_pred)\n        print(f\"Accuracy: {accuracy:.4f}\")\n\n# Define models to train\nmodels = {\n    \"Logistic Regression\": LogisticRegression(),\n    \"SVM\": SVC(),\n    \"Random Forest\": RandomForestClassifier(),\n    \"Multinomial Naive Bayes\": MultinomialNB()\n}\n\n# Evaluate with TF-IDF features\nprint(\"\\nUsing TF-IDF features:\")\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)\ntrain_and_evaluate(models, tfidf_vectorizer, \"TF-IDF\")\n\n# Evaluate with Bag of Words (BoW) features\nprint(\"\\nUsing Bag of Words (BoW) features:\")\nbow_vectorizer = CountVectorizer(max_features=5000)\ntrain_and_evaluate(models, bow_vectorizer, \"BoW\")\n\n# Load the test dataset\ntest_data = pd.read_csv(\"/kaggle/input/test1-1-data/AWT_test_without_labels.csv\")\n\n# Transform test data using the TF-IDF vectorizer\nX_test_tfidf = tfidf_vectorizer.transform(test_data[\"Text\"])\n\n# Make predictions on the test dataset using the best-performing model (e.g., Logistic Regression)\nbest_model = LogisticRegression()  # Replace with your chosen model if needed\nbest_model.fit(tfidf_vectorizer.fit_transform(X_train), y_train)  # Retrain on the full training data\ntest_predictions = best_model.predict(X_test_tfidf)\n\n# Convert predictions back to original label names\nreverse_label_mapping = {v: k for k, v in label_mapping.items()}\ntest_predictions_labels = [reverse_label_mapping[pred] for pred in test_predictions]\n\n# Save predictions to a CSV file\noutput = pd.DataFrame({\"Text\": test_data[\"Text\"], \"Predicted_Class\": test_predictions_labels})\noutput.to_csv(\"test_predictions.csv\", index=False)\nprint(\"Predictions saved to 'test_predictions.csv'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T13:58:01.144486Z","iopub.execute_input":"2025-01-27T13:58:01.144793Z","iopub.status.idle":"2025-01-27T13:58:04.762868Z","shell.execute_reply.started":"2025-01-27T13:58:01.144770Z","shell.execute_reply":"2025-01-27T13:58:04.761800Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd\n# from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n# import torch\n# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import accuracy_score, precision_score, recall_score\n\n# # Load the dataset\n# train_data = pd.read_csv(\"/kaggle/input/train-data/AWT_train.csv\")\n# test_data = pd.read_csv(\"/kaggle/input/test1-1-data/AWT_test_without_labels.csv\")\n\n# # Map the labels\n# label_mapping = {\"Non-Abusive\": 0, \"Abusive\": 1}\n# train_data[\"Class\"] = train_data[\"Class\"].map(label_mapping)\n\n# # Ensure no missing values\n# train_data = train_data.dropna(subset=[\"Class\"])\n\n# # Split the dataset into training and validation sets\n# train_texts, val_texts, train_labels, val_labels = train_test_split(\n#     train_data[\"Text\"], train_data[\"Class\"], test_size=0.2, random_state=42\n# )\n\n# # Initialize the tokenizer\n# tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n\n# # Tokenize the dataset\n# def preprocess_function(texts, labels):\n#     tokenized = tokenizer(list(texts), padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n#     tokenized[\"labels\"] = labels\n#     return tokenized\n\n# train_encodings = preprocess_function(train_texts, list(train_labels))\n# val_encodings = preprocess_function(val_texts, list(val_labels))\n\n# # Convert tokenized data to PyTorch datasets\n# class CustomDataset(torch.utils.data.Dataset):\n#     def __init__(self, encodings):\n#         self.encodings = encodings\n\n#     def __len__(self):\n#         return len(self.encodings[\"input_ids\"])\n\n#     def __getitem__(self, idx):\n#         return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\n# train_dataset = CustomDataset(train_encodings)\n# val_dataset = CustomDataset(val_encodings)\n\n# # Initialize the model\n# model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=1)\n\n# # Define the compute_metrics function\n# def compute_metrics(pred):\n#     predictions, labels = pred\n#     preds = (torch.sigmoid(torch.tensor(predictions)) > 0.5).int()\n#     labels = torch.tensor(labels).int()\n    \n#     accuracy = accuracy_score(labels, preds)\n#     precision = precision_score(labels, preds)\n#     recall = recall_score(labels, preds)\n#     f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    \n#     return {\n#         \"accuracy\": accuracy,\n#         \"precision\": precision,\n#         \"recall\": recall,\n#         \"f1\": f1,\n#     }\n\n# # Define the TrainingArguments\n# training_args = TrainingArguments(\n#     output_dir=\"./results\",               # Output directory\n#     eval_strategy=\"epoch\",                # Evaluate every epoch\n#     save_strategy=\"epoch\",                # Save every epoch\n#     learning_rate=5e-5,                   # Learning rate\n#     per_device_train_batch_size=16,       # Batch size for training\n#     per_device_eval_batch_size=16,        # Batch size for evaluation\n#     num_train_epochs=7,                   # Number of epochs\n#     weight_decay=0.003,                   # Weight decay\n#     logging_dir=\"./logs\",                 # Logging directory\n#     logging_steps=10,                     # Log every 10 steps\n#     report_to=\"none\",                     # Disable W&B logging\n# )\n\n# # Define the Trainer\n# trainer = Trainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=train_dataset,\n#     eval_dataset=val_dataset,\n#     tokenizer=tokenizer,\n#     compute_metrics=compute_metrics,\n# )\n\n# # Train the model\n# trainer.train()\n\n# # Make predictions on the test set\n# test_encodings = preprocess_function(test_data[\"Text\"], [0] * len(test_data))\n# test_dataset = CustomDataset(test_encodings)\n\n# predictions = trainer.predict(test_dataset)\n# preds = torch.sigmoid(torch.tensor(predictions.predictions)).numpy()\n# pred_labels = (preds > 0.5).astype(int).flatten()\n\n# # Save predictions with only \"Id\" and \"Labels\"\n# test_data[\"Predicted_Class\"] = pred_labels\n# test_data[\"Predicted_Class\"] = test_data[\"Predicted_Class\"].map({0: \"Non-Abusive\", 1: \"Abusive\"})\n# test_data.to_csv(\"test_predictions_bert.csv\", index=False)\n# print(\"Predictions saved to 'test_predictions_bert.csv'.\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T15:55:52.016584Z","iopub.execute_input":"2025-01-27T15:55:52.016907Z","iopub.status.idle":"2025-01-27T16:01:52.114054Z","shell.execute_reply.started":"2025-01-27T15:55:52.016883Z","shell.execute_reply":"2025-01-27T16:01:52.113305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import required libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom gensim.models import FastText\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Bidirectional, Dense, Flatten, Dropout\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Load the training dataset\ntrain_data = pd.read_csv(\"/kaggle/input/train-data/AWT_train.csv\")\n\n# Preprocess the data\nprint(\"Number of missing values in 'Class' before cleaning:\", train_data[\"Class\"].isna().sum())\ntrain_data = train_data.dropna(subset=[\"Class\"])\nlabel_mapping = {\"Non-Abusive\": 0, \"Abusive\": 1}\ntrain_data[\"Class\"] = train_data[\"Class\"].map(label_mapping)\ntrain_data = train_data.dropna(subset=[\"Class\"])\nprint(\"Number of missing values in 'Class' after mapping and cleaning:\", train_data[\"Class\"].isna().sum())\n\n# Split the training data into train and validation sets\nX_train, X_val, y_train, y_val = train_test_split(\n    train_data[\"Text\"], train_data[\"Class\"], test_size=0.2, random_state=42\n)\n\n# Tokenize and pad sequences\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_train)\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_val_seq = tokenizer.texts_to_sequences(X_val)\nX_train_padded = pad_sequences(X_train_seq, padding=\"post\")\nX_val_padded = pad_sequences(X_val_seq, padding=\"post\", maxlen=X_train_padded.shape[1])\n\n# Load FastText embeddings\ndef load_embeddings(embedding_dim=100):\n    sentences = [text.split() for text in X_train]\n    model = FastText(sentences, vector_size=embedding_dim, window=5, min_count=1, sg=1)\n    embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n    for word, i in tokenizer.word_index.items():\n        if word in model.wv:\n            embedding_matrix[i] = model.wv[word]\n    return embedding_matrix\n\nembedding_matrix = load_embeddings(embedding_dim=100)\n\n# Define CNN model\ndef cnn_model(input_length, embedding_matrix):\n    model = Sequential([\n        Embedding(input_dim=embedding_matrix.shape[0], \n                  output_dim=embedding_matrix.shape[1],\n                  weights=[embedding_matrix], \n                  input_length=input_length, \n                  trainable=False),\n        Conv1D(filters=128, kernel_size=5, activation=\"relu\"),\n        MaxPooling1D(pool_size=2),\n        Flatten(),\n        Dense(128, activation=\"relu\"),\n        Dropout(0.5),\n        Dense(1, activation=\"sigmoid\")\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model\n\n# Define BiLSTM model\ndef bilstm_model(input_length, embedding_matrix):\n    model = Sequential([\n        Embedding(input_dim=embedding_matrix.shape[0], \n                  output_dim=embedding_matrix.shape[1],\n                  weights=[embedding_matrix], \n                  input_length=input_length, \n                  trainable=False),\n        Bidirectional(LSTM(128, return_sequences=True)),\n        Flatten(),\n        Dense(128, activation=\"relu\"),\n        Dropout(0.5),\n        Dense(1, activation=\"sigmoid\")\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model\n\n# Define CNN+BiLSTM model\ndef cnn_bilstm_model(input_length, embedding_matrix):\n    model = Sequential([\n        Embedding(input_dim=embedding_matrix.shape[0], \n                  output_dim=embedding_matrix.shape[1],\n                  weights=[embedding_matrix], \n                  input_length=input_length, \n                  trainable=False),\n        Conv1D(filters=128, kernel_size=5, activation=\"relu\"),\n        MaxPooling1D(pool_size=2),\n        Bidirectional(LSTM(128, return_sequences=True)),\n        Flatten(),\n        Dense(128, activation=\"relu\"),\n        Dropout(0.5),\n        Dense(1, activation=\"sigmoid\")\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model\n\n# Train and evaluate models\ndef train_and_evaluate_dl_model(model, model_name):\n    print(f\"\\nTraining {model_name}...\")\n    model.fit(X_train_padded, y_train, epochs=5, batch_size=32, validation_data=(X_val_padded, y_val))\n    y_val_pred = (model.predict(X_val_padded) > 0.5).astype(\"int32\").flatten()\n    print(f\"\\nValidation Results for {model_name}:\")\n    print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred, digits=4))\n    accuracy = accuracy_score(y_val, y_val_pred)\n    print(f\"Accuracy: {accuracy:.4f}\")\n\n# Train CNN\ncnn = cnn_model(X_train_padded.shape[1], embedding_matrix)\ntrain_and_evaluate_dl_model(cnn, \"CNN\")\n\n# Train BiLSTM\nbilstm = bilstm_model(X_train_padded.shape[1], embedding_matrix)\ntrain_and_evaluate_dl_model(bilstm, \"BiLSTM\")\n\n# Train CNN+BiLSTM\ncnn_bilstm = cnn_bilstm_model(X_train_padded.shape[1], embedding_matrix)\ntrain_and_evaluate_dl_model(cnn_bilstm, \"CNN+BiLSTM\")\n\n# Load the test dataset\ntest_data = pd.read_csv(\"/kaggle/input/test1-1-data/AWT_test_without_labels.csv\")\nX_test_seq = tokenizer.texts_to_sequences(test_data[\"Text\"])\nX_test_padded = pad_sequences(X_test_seq, padding=\"post\", maxlen=X_train_padded.shape[1])\n\n# Make predictions on test dataset using the best-performing model (e.g., CNN+BiLSTM)\nbest_model = cnn_bilstm  # Replace with your chosen model\ntest_predictions = (best_model.predict(X_test_padded) > 0.5).astype(\"int32\").flatten()\n\n# Convert predictions back to original label names\nreverse_label_mapping = {v: k for k, v in label_mapping.items()}\ntest_predictions_labels = [reverse_label_mapping[pred] for pred in test_predictions]\n\n# Save predictions to a CSV file\noutput = pd.DataFrame({\"Text\": test_data[\"Text\"], \"Predicted_Class\": test_predictions_labels})\noutput.to_csv(\"test_predictions.csv\", index=False)\nprint(\"Predictions saved to 'test_predictions.csv'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T03:32:57.481291Z","iopub.execute_input":"2025-01-28T03:32:57.481549Z","iopub.status.idle":"2025-01-28T03:34:09.694738Z","shell.execute_reply.started":"2025-01-28T03:32:57.481518Z","shell.execute_reply":"2025-01-28T03:34:09.693994Z"}},"outputs":[{"name":"stdout","text":"Number of missing values in 'Class' before cleaning: 0\nNumber of missing values in 'Class' after mapping and cleaning: 0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nTraining CNN...\nEpoch 1/5\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.4997 - loss: 0.7009 - val_accuracy: 0.5466 - val_loss: 0.6895\nEpoch 2/5\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5524 - loss: 0.6861 - val_accuracy: 0.5466 - val_loss: 0.6865\nEpoch 3/5\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5815 - loss: 0.6710 - val_accuracy: 0.5341 - val_loss: 0.6858\nEpoch 4/5\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5653 - loss: 0.6692 - val_accuracy: 0.5627 - val_loss: 0.6848\nEpoch 5/5\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5858 - loss: 0.6512 - val_accuracy: 0.5681 - val_loss: 0.6835\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n\nValidation Results for CNN:\nClassification Report:\n               precision    recall  f1-score   support\n\n         0.0     0.5685    0.5907    0.5794       281\n         1.0     0.5677    0.5451    0.5562       277\n\n    accuracy                         0.5681       558\n   macro avg     0.5681    0.5679    0.5678       558\nweighted avg     0.5681    0.5681    0.5679       558\n\nAccuracy: 0.5681\n\nTraining BiLSTM...\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.4832 - loss: 0.7245 - val_accuracy: 0.5072 - val_loss: 0.6926\nEpoch 2/5\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5017 - loss: 0.7131 - val_accuracy: 0.5018 - val_loss: 0.6921\nEpoch 3/5\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5151 - loss: 0.6951 - val_accuracy: 0.5179 - val_loss: 0.6915\nEpoch 4/5\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5255 - loss: 0.6910 - val_accuracy: 0.5036 - val_loss: 0.6930\nEpoch 5/5\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5280 - loss: 0.6954 - val_accuracy: 0.4964 - val_loss: 0.6926\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\nValidation Results for BiLSTM:\nClassification Report:\n               precision    recall  f1-score   support\n\n         0.0     0.0000    0.0000    0.0000       281\n         1.0     0.4964    1.0000    0.6635       277\n\n    accuracy                         0.4964       558\n   macro avg     0.2482    0.5000    0.3317       558\nweighted avg     0.2464    0.4964    0.3294       558\n\nAccuracy: 0.4964\n\nTraining CNN+BiLSTM...\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.5238 - loss: 0.7119 - val_accuracy: 0.5072 - val_loss: 0.6930\nEpoch 2/5\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4915 - loss: 0.6959 - val_accuracy: 0.5036 - val_loss: 0.6928\nEpoch 3/5\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5088 - loss: 0.6930 - val_accuracy: 0.5036 - val_loss: 0.6947\nEpoch 4/5\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5333 - loss: 0.6898 - val_accuracy: 0.5090 - val_loss: 0.7250\nEpoch 5/5\n\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5280 - loss: 0.6982 - val_accuracy: 0.5681 - val_loss: 0.6884\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n\nValidation Results for CNN+BiLSTM:\nClassification Report:\n               precision    recall  f1-score   support\n\n         0.0     0.5699    0.5801    0.5750       281\n         1.0     0.5662    0.5560    0.5610       277\n\n    accuracy                         0.5681       558\n   macro avg     0.5681    0.5680    0.5680       558\nweighted avg     0.5681    0.5681    0.5680       558\n\nAccuracy: 0.5681\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\nPredictions saved to 'test_predictions.csv'.\n","output_type":"stream"}],"execution_count":1}]}